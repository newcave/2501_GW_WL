import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ ë° ë°ì´í„° ë¡œë”©
@st.cache_data
def load_data(file):
    data = pd.read_excel(file, header=2)
    data.columns = data.columns.str.strip()
    return data

@st.cache_data
def load_default_data():
    data = pd.read_excel("GW_001.xlsx", header=2)
    data.columns = data.columns.str.strip()
    return data

# âš™ï¸ ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.title("ğŸ›°ï¸ ì§€í•˜ìˆ˜ìœ„ ì˜ˆì¸¡ ì„¤ì •")
use_default = st.sidebar.checkbox("âœ… ê¸°ë³¸ ë°ì´í„°(GW_001.xlsx) ì‚¬ìš©")
uploaded_file = st.sidebar.file_uploader("ğŸ“¤ ì§€ì  ë°ì´í„° ì—…ë¡œë“œ (Excel íŒŒì¼)", type=["xlsx"])
lead_time = st.sidebar.slider("â³ ë¦¬ë“œ íƒ€ì„ (ì˜ˆì¸¡ ê¸°ê°„, ì¼)", min_value=1, max_value=30, value=7)
look_back = st.sidebar.slider("ğŸ” ë£©ë°± ê¸°ê°„ (ê³¼ê±° ë°ì´í„° ì‚¬ìš© ê¸°ê°„, ì¼)", min_value=1, max_value=365, value=30)
n_estimators = st.sidebar.slider("ğŸ› ï¸ # of Estimators (í•˜ì´í¼íŒŒë¼ë¯¸í„°)", min_value=10, max_value=500, step=10, value=100)
split_ratio = st.sidebar.slider("ğŸ“Š í•™ìŠµ:í…ŒìŠ¤íŠ¸ ì…‹ ë¹„ìœ¨ (%)", min_value=10, max_value=90, value=80, step=5)

# ğŸ“Š ë°ì´í„° ë¡œë”© ë° ì¶œë ¥
if uploaded_file or use_default:
    data = load_data(uploaded_file) if uploaded_file else load_default_data()
    wl_column = 'ê³„ì¸¡ìˆ˜ìœ„'
    if wl_column in data.columns:
        data = data.sort_values(wl_column).reset_index(drop=True)
        st.success("âœ… raw data ì²˜ë¦¬ ë° ëª¨ë¸ ì‹¤í–‰ âœ…")
    else:
        st.error("âŒ ë°ì´í„°ì— 'ê³„ì¸¡ìˆ˜ìœ„' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ì—…ë¡œë“œí•œ ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

    with st.expander("ğŸ” Raw ë°ì´í„° ë³´ê¸°", expanded=True):
        st.write(data)
        st.write(f"ğŸ“‹ **ë°ì´í„° ì»¬ëŸ¼ëª…:** {list(data.columns)}")

    st.subheader("ğŸ“ˆ ë…ë¦½ë³€ìˆ˜ ì„ íƒ")
    independent_vars = st.multiselect("âœ… ì‚¬ìš©í•  ë…ë¦½ë³€ìˆ˜ ì„ íƒ:", options=list(data.columns), default=[col for col in ["ìˆ˜ì˜¨", "ì „ë„ë„"] if col in data.columns])
    st.subheader("ğŸ¯ ì˜ˆì¸¡ë³€ìˆ˜ ì„ íƒ")
    target_var = st.selectbox("âœ… ì˜ˆì¸¡í•  ë³€ìˆ˜ ì„ íƒ:", options=list(data.columns), index=list(data.columns).index(wl_column))

    # ì˜¤ê²°ì¸¡ ë° ì´ìƒì¹˜ ì²˜ë¦¬ ì„¹ì…˜
    handle_outliers = st.checkbox("ğŸ› ï¸ ì˜¤ê²°ì¸¡ ë° ì´ìƒì¹˜ ì²˜ë¦¬ ì ìš©")
    threshold = st.number_input("ğŸ“‰ ì¢…ì†ë³€ìˆ˜ ìµœì†Œê°’ ì„¤ì •", min_value=0.0, value=0.1, step=0.01)
    if handle_outliers:
        st.info(f"ğŸ” ì¢…ì†ë³€ìˆ˜ì—ì„œ {threshold} ì´í•˜ ê°’ì„ ì œê±°í•©ë‹ˆë‹¤.")
        data = data[data[target_var] > threshold]

    if st.button("ğŸš€ ë³€ìˆ˜ ì„¤ì • ì™„ë£Œ"):
        with st.expander("ğŸ“Œ ì„ íƒí•œ ë³€ìˆ˜ ë³´ê¸°", expanded=False):
            st.write(f"âœ… **ì„ íƒí•œ ë…ë¦½ë³€ìˆ˜:** {independent_vars}")
            st.write(f"ğŸ¯ **ì˜ˆì¸¡ ë³€ìˆ˜:** {target_var}")
            st.write(f"â³ **ë¦¬ë“œ íƒ€ì„:** {lead_time}ì¼, ğŸ” **ë£©ë°± ê¸°ê°„:** {look_back}ì¼, ğŸ› ï¸ **Estimator ìˆ˜:** {n_estimators}")
#        split_ratio = st.sidebar.slider("ğŸ“Š í•™ìŠµ:í…ŒìŠ¤íŠ¸ ì…‹ ë¹„ìœ¨ (%)", min_value=10, max_value=90, value=80, step=5)
        st.subheader("ğŸ” ê¸°ë³¸ EDA")
        fig, axes = plt.subplots(1, 3, figsize=(18, 5))
        for i, var in enumerate(independent_vars[:3]):
            sns.histplot(data[var], kde=True, bins=30, ax=axes[i])
            axes[i].set_title(f'{var} Distribution')
        st.pyplot(fig)
        
        fig_corr, ax_corr = plt.subplots(figsize=(8, 6))
        sns.heatmap(data[independent_vars + [target_var]].corr(), annot=True, cmap='coolwarm', ax=ax_corr)
        ax_corr.set_title('Feature Correlation Heatmap')
        st.pyplot(fig_corr)

    if st.button("ğŸ“Š ëª¨ë¸ ì‹¤í–‰"):
        test_size = 1 - (split_ratio / 100)  # í•™ìŠµ ë¹„ìœ¨ì„ í…ŒìŠ¤íŠ¸ ë¹„ìœ¨ë¡œ ë³€í™˜
        X = data[independent_vars].apply(pd.to_numeric, errors='coerce').dropna()
        y = pd.to_numeric(data[target_var], errors='coerce').loc[X.index].dropna()
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
#    if st.button("ğŸ“Š ëª¨ë¸ ì‹¤í–‰"):
#        X = data[independent_vars].apply(pd.to_numeric, errors='coerce').dropna()
#        y = pd.to_numeric(data[target_var], errors='coerce').loc[X.index].dropna()
#        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)
        model = RandomForestRegressor(n_estimators=n_estimators, random_state=42)
        model.fit(X_train, y_train)
        
        y_train_pred, y_pred = model.predict(X_train), model.predict(X_test)
        train_rmse, test_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred)), np.sqrt(mean_squared_error(y_test, y_pred))
        train_r2, test_r2 = r2_score(y_train, y_train_pred), r2_score(y_test, y_pred)

        fig, axes = plt.subplots(1, 3, figsize=(24, 6))
        axes[0].plot(y_train.values, label='ì‹¤ì œê°’')
        axes[0].plot(y_train_pred, label='ì˜ˆì¸¡ê°’', linestyle='--')
        axes[0].set_title(f'Training Set\nRMSE: {train_rmse:.2f}, R2: {train_r2:.2f}')
        axes[0].legend()

        axes[1].plot(y_test.values, label='ì‹¤ì œê°’')
        axes[1].plot(y_pred, label='ì˜ˆì¸¡ê°’', linestyle='--')
        axes[1].set_title(f'Testing Set\nRMSE: {test_rmse:.2f}, R2: {test_r2:.2f}')
        axes[1].legend()

        axes[2].scatter(y_test, y_pred, alpha=0.6, edgecolor='k')
        axes[2].plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')
        axes[2].set_title(f'Actual vs Predicted\nR2: {test_r2:.2f}')
        st.pyplot(fig)
else:
    st.info("ğŸ’¡ **K-water AI LAB x Groundwater Research Team Collaboration.**")
    col1, col2 = st.columns(2)
    with col1:
        st.image("FIG2.png", caption="ğŸ“ ìœ„ì¹˜ë„ ë° ì—¼ë¶„ ë¶„í¬ë„")
    with col2:
        st.video("media.mp4")
